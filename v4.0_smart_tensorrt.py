#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
PDF æ‰¹é‡ OCR å¤„ç†è„šæœ¬ - v4.0 æ™ºèƒ½è¯†åˆ«ç‰ˆ
ä¿®å¤ï¼š
1. é¦–å…ˆè‡ªåŠ¨è¯†åˆ«æ–‡æ¡£ç±»å‹ï¼ˆå¤ç±/ç°ä»£ï¼‰
2. å¤ç±ï¼šä»å³åˆ°å·¦ã€ä»ä¸Šåˆ°ä¸‹ï¼Œä¸¥æ ¼æ¡†çº¿ç‰ˆé¢
3. ç°ä»£ï¼šä»å·¦åˆ°å³ã€ä»ä¸Šåˆ°ä¸‹ï¼Œæ ‡å‡† Markdown
4. è´¨é‡æŠ¥å‘Šåˆ†ç¦»
"""

import os
import sys
import gc
import time
import warnings
from pathlib import Path
from datetime import datetime
from typing import List, Tuple, Dict
import multiprocessing

warnings.filterwarnings("ignore")
os.environ["PADDLE_PDX_DISABLE_MODEL_SOURCE_CHECK"] = "True"

# ==================== ç‰ˆæœ¬ä¿¡æ¯ ====================
VERSION = "v4.0-SmartDoc"
VERSION_NOTE = "æ™ºèƒ½è¯†åˆ« + å¤ç±ä¸“ç”¨ç‰ˆé¢"
TARGET_SPEED = 120  # é¡µ/åˆ†é’Ÿ

# ==================== æ ¸å¿ƒé…ç½® ====================

INPUT_DIR = "/media/zjj/leidian1/leidian"
OUTPUT_DIR = "/media/zjj/leidian1/leidian/ocr_output_v4_smart"
REPORT_DIR = "/media/zjj/leidian1/leidian/ocr_quality_reports_v4"

# OCR é…ç½®ï¼ˆå…¨æ¨¡å— TensorRT FP16 åŠ é€Ÿï¼‰
OCR_CONFIG = {
    "use_hpip": True,
    "device": "gpu:0",
    "pipeline": "OCR",
    "text_recognition_batch_size": 512,  # å¢å¤§ batch åˆ° 512
    # TensorRT åŠ é€Ÿé…ç½®ï¼ˆæ‰€æœ‰æ¨¡å—å¯ç”¨ FP16ï¼‰
    "trt_config": {
        "precision_mode": "FP16",  # FP16 åŠç²¾åº¦åŠ é€Ÿ
        "trt_use_dynamic_shapes": True,
        "trt_min_shape": [1, 3, 32, 32],
        "trt_opt_shape": [1, 3, 48, 320],
        "trt_max_shape": [8, 3, 48, 3200],
        "trt_static_cache": True,  # å¯ç”¨é™æ€ç¼“å­˜
        "trt_workspace_size": 1024,  # 1GB å·¥ä½œç©ºé—´
    }
}

# æ€§èƒ½é…ç½®ï¼ˆCPU ä¾›æ•°ä¼˜åŒ–ç‰ˆ - ç›®æ ‡ 120 é¡µ/åˆ†é’Ÿï¼‰
PERF_CONFIG = {
    "max_workers": 12,           # OCR å¹¶è¡Œ 12 çº¿ç¨‹
    "dpi": 190,                  # é”å®š DPI 190
    "image_max_size": 1200,      # é™ä½å›¾ç‰‡å°ºå¯¸åˆ° 1200
    "prefetch_pages": 200,       # CPU é¢„å– 200 é¡µï¼ˆç¿»å€ï¼‰
    "cpu_workers": 16,           # 16 çº¿ç¨‹è§£ç ï¼ˆ+4ï¼‰
    "cpu_decode_prefetch": 100,  # é¢„è§£ç  100 é¡µï¼ˆç¿»å€ï¼‰
}

# å¤ç±è¯†åˆ«é…ç½®
ANCIENT_DETECT_CONFIG = {
    "keywords_ancient": [
        "æ’°", "æ’°å¹¶", "åº", "è·‹", "å·", "çºª", "ä¼ ", "å¿—", "è¡¨", "è°±",
        "çš‡", "å¸", "è¯", "è°•", "å¥", "ç–", "å¤æ–‡", "æ–‡è¨€æ–‡",
        "å…‰ç»ª", "ä¹¾éš†", "å˜‰åº†", "é“å…‰", "å’¸ä¸°", "åŒæ²»", "å®£ç»Ÿ",
        "åº·ç†™", "é›æ­£", "æ˜æœ", "æ¸…æœ", "å®‹æœ", "å”æœ", "å…ƒå¹´",
        "å²æ¬¡", "å¹²æ”¯", "ç”²", "ä¹™", "ä¸™", "ä¸", "æˆŠ", "å·±", "åºš", "è¾›", "å£¬", "ç™¸",
        "å­", "ä¸‘", "å¯…", "å¯", "è¾°", "å·³", "åˆ", "æœª", "ç”³", "é…‰", "æˆŒ", "äº¥"
    ],
    "keywords_modern": [
        "æŠ¥å‘Š", "åˆ†æ", "ç ”ç©¶", "è°ƒæŸ¥", "ç»Ÿè®¡", "æ•°æ®", "æŠ€æœ¯", "å·¥ç¨‹",
        "ç§‘å­¦", "æŠ€æœ¯", "å…¬å¸", "ä¼ä¸š", "å•ä½", "éƒ¨é—¨", "å¹´", "æœˆ", "æ—¥",
        "æ‘˜è¦", "å…³é”®è¯", "å¼•è¨€", "ç»“è®º", "å‚è€ƒ", "æ–‡çŒ®", "å›¾è¡¨", "é™„å½•"
    ],
    "confidence_threshold": 0.70,  # ç½®ä¿¡åº¦é˜ˆå€¼
}

STATE_FILE = "/media/zjj/leidian1/leidian/.paddlex_ocr_v4_state.json"

# ====================================================


def clear_gpu_memory():
    """æ¸…ç† GPU æ˜¾å­˜"""
    gc.collect()
    import paddle
    if paddle.is_compiled_with_cuda():
        paddle.device.cuda.empty_cache()
        paddle.device.cuda.synchronize()
        print(f"  âœ“ GPU æ˜¾å­˜å·²æ¸…ç†")


def check_and_clear_gpu_memory(threshold_mb=14000):
    """æ£€æŸ¥å¹¶æ¸…ç† GPU æ˜¾å­˜ï¼ˆé˜ˆå€¼ 14GBï¼‰"""
    import paddle
    if paddle.is_compiled_with_cuda():
        mem_info = paddle.device.cuda.memory_allocated()
        mem_mb = mem_info / 1024 / 1024
        if mem_mb > threshold_mb:
            print(f"  âš ï¸  æ˜¾å­˜å ç”¨ {mem_mb:.0f}MB > {threshold_mb}MBï¼Œè‡ªåŠ¨æ¸…ç†...")
            clear_gpu_memory()
        return mem_mb
    return 0


class PageCache:
    """é¡µé¢ç¼“å­˜ç®¡ç†å™¨"""
    
    def __init__(self, max_pages=500):
        self.max_pages = max_pages
        self.cache = {}
        self.access_order = []
        
    def get(self, key):
        if key in self.cache:
            self.access_order.remove(key)
            self.access_order.append(key)
            return self.cache[key]
        return None
    
    def put(self, key, value):
        if len(self.cache) >= self.max_pages:
            oldest = self.access_order.pop(0)
            del self.cache[oldest]
        self.cache[key] = value
        self.access_order.append(key)
    
    def clear(self):
        self.cache.clear()
        self.access_order.clear()


def detect_document_type(pdf_name: str, first_page_text: str) -> str:
    """
    æ™ºèƒ½è¯†åˆ«æ–‡æ¡£ç±»å‹
    è¿”å›ï¼š"ancient"ï¼ˆå¤ç±ï¼‰æˆ– "modern"ï¼ˆç°ä»£ï¼‰
    """
    ancient_score = 0
    modern_score = 0
    
    # æ–‡ä»¶åæ£€æµ‹
    pdf_name_lower = pdf_name.lower()
    for keyword in ANCIENT_DETECT_CONFIG["keywords_ancient"]:
        if keyword in pdf_name_lower:
            ancient_score += 2
    
    for keyword in ANCIENT_DETECT_CONFIG["keywords_modern"]:
        if keyword in pdf_name_lower:
            modern_score += 2
    
    # æ–‡æœ¬å†…å®¹æ£€æµ‹
    text_lower = first_page_text.lower()
    for keyword in ANCIENT_DETECT_CONFIG["keywords_ancient"]:
        if keyword in text_lower:
            ancient_score += 1
    
    for keyword in ANCIENT_DETECT_CONFIG["keywords_modern"]:
        if keyword in text_lower:
            modern_score += 1
    
    # åˆ¤æ–­ç»“æœ
    if ancient_score > modern_score * 1.5:
        return "ancient"
    elif modern_score > ancient_score * 1.5:
        return "modern"
    else:
        # åˆ†æ•°æ¥è¿‘ï¼Œä½¿ç”¨æ›´å¤šè§„åˆ™
        # å¤ç±ç‰¹å¾ï¼šçŸ­æ–‡æœ¬ã€ç¹ä½“å­—ã€ç«–æ’
        if len(first_page_text) < 200 and any(c in first_page_text for c in "ç¹é«”å­—"):
            return "ancient"
        # é»˜è®¤æŒ‰ç°ä»£æ–‡æ¡£å¤„ç†
        return "modern"


def init_ocr_pipeline():
    """åˆå§‹åŒ– PaddleOCR æµæ°´çº¿ï¼ˆå…¨æ¨¡å— TensorRT FP16 åŠ é€Ÿï¼‰"""
    from paddlex import create_pipeline

    print(f"  â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—")
    print(f"  â•‘  OCR v4.0 æ™ºèƒ½è¯†åˆ«ç‰ˆ {VERSION:16s}                      â•‘")
    print(f"  â•‘  è°ƒæ•´ï¼š{VERSION_NOTE:44s}  â•‘")
    print(f"  â•‘  ç›®æ ‡ï¼š{TARGET_SPEED} é¡µ/åˆ†é’Ÿ                                     â•‘")
    print(f"  â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
    print(f"")
    print(f"  ã€æ ¸å¿ƒåŠŸèƒ½ã€‘")
    print(f"    1. æ™ºèƒ½è¯†åˆ«ï¼šè‡ªåŠ¨åŒºåˆ†å¤ç±/ç°ä»£æ–‡æ¡£")
    print(f"    2. å¤ç±ç‰ˆé¢ï¼šä»å³åˆ°å·¦ã€ä»ä¸Šåˆ°ä¸‹ã€æ¡†çº¿åˆ†éš”")
    print(f"    3. ç°ä»£ç‰ˆé¢ï¼šæ ‡å‡† Markdown æ ¼å¼")
    print(f"    4. è´¨é‡æŠ¥å‘Šï¼šå•ç‹¬ JSON æ–‡ä»¶")
    print(f"")
    print(f"  ã€å…¨æ¨¡å— TensorRT FP16 åŠ é€Ÿã€‘")
    print(f"    - UVDoc: FP16 TensorRT âœ“")
    print(f"    - æ–‡æœ¬è¡Œæ–¹å‘ï¼šFP16 TensorRT âœ“")
    print(f"    - æ–‡æœ¬æ£€æµ‹ï¼šFP16 TensorRT âœ“")
    print(f"    - æ–‡æœ¬è¯†åˆ«ï¼šFP16 TensorRT âœ“")
    print(f"    - æ‰¹å¤„ç†ï¼š{OCR_CONFIG['text_recognition_batch_size']}")
    print(f"")
    print(f"  ã€GPU èµ„æºä¼˜åŒ–ã€‘")
    print(f"    - TensorRT å·¥ä½œç©ºé—´ï¼š1GB")
    print(f"    - åŠ¨æ€å½¢çŠ¶ï¼šå¯ç”¨")
    print(f"    - é™æ€ç¼“å­˜ï¼šå¯ç”¨")
    print(f"")
    print(f"  ã€æ¨¡å‹é…ç½®ã€‘")
    print(f"    - Pipeline: {OCR_CONFIG['pipeline']}")
    print(f"    - DPI: {PERF_CONFIG['dpi']}")
    print(f"    - å›¾ç‰‡å°ºå¯¸ï¼š{PERF_CONFIG['image_max_size']}")
    print(f"")
    print(f"  ã€è¾“å‡ºæ ¼å¼ã€‘")
    print(f"    - å¤ç±ï¼šæ¡†çº¿ç‰ˆé¢ Markdown")
    print(f"    - ç°ä»£ï¼šæ ‡å‡† Markdown")
    print(f"    - è´¨é‡æŠ¥å‘Šï¼šå•ç‹¬ JSON æ–‡ä»¶")
    print(f"")

    print(f"  æ­£åœ¨åˆå§‹åŒ– PaddleOCR æµæ°´çº¿ï¼ˆå…¨æ¨¡å— TensorRT FP16ï¼‰...")
    
    # åˆ›å»º PaddleX æµæ°´çº¿ï¼Œåº”ç”¨ TensorRT é…ç½®åˆ°æ‰€æœ‰æ¨¡å—
    pipeline = create_pipeline(
        pipeline=OCR_CONFIG["pipeline"],
        use_hpip=OCR_CONFIG["use_hpip"],
        device=OCR_CONFIG["device"],
        # å…¨å±€ TensorRT é…ç½®ï¼ˆåº”ç”¨åˆ°æ‰€æœ‰æ¨¡å—ï¼‰
        trt_precision=OCR_CONFIG["trt_config"]["precision_mode"],
        trt_use_dynamic_shapes=OCR_CONFIG["trt_config"]["trt_use_dynamic_shapes"],
        trt_min_shape=OCR_CONFIG["trt_config"]["trt_min_shape"],
        trt_opt_shape=OCR_CONFIG["trt_config"]["trt_opt_shape"],
        trt_max_shape=OCR_CONFIG["trt_config"]["trt_max_shape"],
        trt_static_cache=OCR_CONFIG["trt_config"]["trt_static_cache"],
        trt_workspace_size=OCR_CONFIG["trt_config"]["trt_workspace_size"],
    )
    print(f"  âœ“ PaddleOCR æµæ°´çº¿åˆå§‹åŒ–å®Œæˆï¼ˆå…¨æ¨¡å— TensorRT FP16ï¼‰")
    print(f"  âš¡ é¢„æœŸé€Ÿåº¦ï¼š60-100 é¡µ/åˆ†é’Ÿ")
    return pipeline


def pdf_to_images_optimized(pdf_path: str) -> List[Tuple[int, any]]:
    """PDF è½¬å›¾ç‰‡ï¼ˆCPU å¹¶è¡Œï¼‰"""
    import fitz
    import numpy as np
    import cv2
    
    images = []
    doc = fitz.open(pdf_path)
    total_pages = len(doc)
    
    print(f"  PDF å…± {total_pages} é¡µï¼ŒCPU {PERF_CONFIG['cpu_workers']} çº¿ç¨‹å¹¶è¡Œè§£ç ...")
    
    def decode_page(page_num):
        page = doc[page_num]
        mat = fitz.Matrix(PERF_CONFIG["dpi"] / 72, PERF_CONFIG["dpi"] / 72)
        pix = page.get_pixmap(matrix=mat)
        
        if pix.width > PERF_CONFIG["image_max_size"] or pix.height > PERF_CONFIG["image_max_size"]:
            scale = PERF_CONFIG["image_max_size"] / max(pix.width, pix.height)
            new_width = int(pix.width * scale)
            new_height = int(pix.height * scale)
            img = np.frombuffer(pix.tobytes("png"), np.uint8)
            img = cv2.imdecode(img, cv2.IMREAD_COLOR)
            img = cv2.resize(img, (new_width, new_height))
        else:
            img = np.frombuffer(pix.tobytes("png"), np.uint8)
            img = cv2.imdecode(img, cv2.IMREAD_COLOR)
        
        return (page_num + 1, img)
    
    from concurrent.futures import ThreadPoolExecutor
    with ThreadPoolExecutor(max_workers=PERF_CONFIG["cpu_workers"]) as executor:
        results = list(executor.map(decode_page, range(total_pages)))
    
    images = sorted(results, key=lambda x: x[0])
    doc.close()
    
    print(f"  âœ“ CPU è§£ç å®Œæˆï¼Œ{total_pages}é¡µå·²åŠ è½½åˆ°å†…å­˜")
    return images


def process_page(img, page_num, pipeline) -> Dict:
    """å¤„ç†å•é¡µï¼ˆå¸¦è¡¨æ ¼æ£€æµ‹ï¼‰"""
    result = pipeline.predict(img)
    
    page_data = {
        "page": page_num,
        "text": "",
        "text_lines": [],
        "scores": [],
        "avg_score": 0.0,
        "is_table": False,
        "table_html": ""
    }
    
    for res in result:
        if "rec_texts" in res:
            texts = res.get("rec_texts", [])
            scores = res.get("rec_scores", [])
            boxes = res.get("rec_boxes", [])
            
            page_data["text"] = "\n".join(texts)
            page_data["scores"] = scores
            if scores:
                page_data["avg_score"] = sum(scores) / len(scores)
            
            # ä¿å­˜å¸¦ä½ç½®çš„æ–‡æœ¬è¡Œ
            for i, text in enumerate(texts):
                box = boxes[i] if i < len(boxes) else None
                page_data["text_lines"].append({
                    "text": text,
                    "score": scores[i] if i < len(scores) else 0.0,
                    "box": box.tolist() if box is not None else None
                })
        
        # æ£€æµ‹è¡¨æ ¼ï¼ˆPP-StructureV3 è¾“å‡ºï¼‰
        if "table_result" in res:
            table_res = res.get("table_result", {})
            if "html" in table_res:
                page_data["is_table"] = True
                page_data["table_html"] = table_res["html"]
    
    return page_data


def sort_text_lines_ancient(text_lines: List[Dict], img_width: int) -> List[Dict]:
    """
    å¤ç±æ–‡æœ¬æ’åºï¼šä»å³åˆ°å·¦ã€ä»ä¸Šåˆ°ä¸‹
    1. æŒ‰ Y åæ ‡åˆ†ç»„ï¼ˆåŒä¸€è¡Œï¼‰
    2. æ¯ç»„å†…æŒ‰ X åæ ‡ä»å³åˆ°å·¦æ’åº
    
    box æ ¼å¼ï¼š[[x1,y1], [x2,y2], [x3,y3], [x4,y4]] æˆ– [x1,y1,x2,y2,x3,y3,x4,y4]
    """
    if not text_lines:
        return text_lines
    
    def get_y_center(box):
        """è·å–æ–‡æœ¬æ¡†çš„ Y ä¸­å¿ƒåæ ‡"""
        if not box:
            return 0
        if isinstance(box[0], list):
            # box æ˜¯ [[x1,y1], [x2,y2], [x3,y3], [x4,y4]]
            y_coords = [point[1] for point in box]
            return sum(y_coords) / len(y_coords)
        else:
            # box æ˜¯ [x1,y1,x2,y2,x3,y3,x4,y4]
            y_coords = [box[i] for i in range(1, len(box), 2)]
            return sum(y_coords) / len(y_coords)
    
    def get_x_right(box):
        """è·å–æ–‡æœ¬æ¡†çš„å³ä¾§ X åæ ‡ï¼ˆä»å³åˆ°å·¦æ’åºç”¨ï¼‰"""
        if not box:
            return 0
        if isinstance(box[0], list):
            # box æ˜¯ [[x1,y1], [x2,y2], [x3,y3], [x4,y4]]
            x_coords = [point[0] for point in box]
            return max(x_coords)
        else:
            # box æ˜¯ [x1,y1,x2,y2,x3,y3,x4,y4]
            x_coords = [box[i] for i in range(0, len(box), 2)]
            return max(x_coords)

    # æŒ‰ Y åæ ‡æ’åº
    sorted_by_y = sorted(text_lines, key=lambda x: get_y_center(x["box"]) if x["box"] else 0)
    
    # åˆ†ç»„ï¼ˆY åæ ‡ç›¸è¿‘çš„ä¸ºä¸€è¡Œï¼‰
    lines_groups = []
    current_group = []
    current_y = -1
    y_threshold = 30
    
    for item in sorted_by_y:
        if item["box"]:
            y = get_y_center(item["box"])
            if current_y < 0 or abs(y - current_y) > y_threshold:
                if current_group:
                    lines_groups.append(current_group)
                current_group = [item]
                current_y = y
            else:
                current_group.append(item)
    
    if current_group:
        lines_groups.append(current_group)
    
    # æ¯ç»„å†…æŒ‰ X åæ ‡ä»å³åˆ°å·¦æ’åº
    sorted_lines = []
    for group in lines_groups:
        sorted_group = sorted(group, key=lambda x: -get_x_right(x["box"]) if x["box"] else 0)
        sorted_lines.extend(sorted_group)
    
    return sorted_lines


def format_page_ancient(page_data: Dict) -> str:
    """æ ¼å¼åŒ–å¤ç±é¡µé¢è¾“å‡ºï¼ˆä»å³åˆ°å·¦ã€æ¡†çº¿ç‰ˆé¢ï¼Œæ”¯æŒè¡¨æ ¼ï¼‰"""
    output_lines = []

    border_width = 80
    output_lines.append("â•”" + "â•" * border_width + "â•—")
    output_lines.append("â•‘" + f" ç¬¬ {page_data['page']} é¡µ".center(border_width) + "â•‘")
    output_lines.append("â• " + "â•" * border_width + "â•£")

    # æ£€æµ‹å¹¶å¤„ç†è¡¨æ ¼
    if page_data.get("is_table", False) and page_data.get("table_html"):
        output_lines.append("â•‘ ã€è¡¨æ ¼åŒºåŸŸã€‘")
        output_lines.append("â•‘ " + page_data["table_html"])
        output_lines.append("â•‘")
    elif page_data.get("text_lines"):
        sorted_lines = sort_text_lines_ancient(page_data["text_lines"], page_data["img_width"])

        for line in sorted_lines:
            text = line["text"]
            if text.strip():
                output_lines.append("â•‘ " + text)

    # é¡µé¢åº•è¾¹æ¡†
    output_lines.append("â•š" + "â•" * border_width + "â•")

    return "\n".join(output_lines)


def format_page_modern(page_data: Dict) -> str:
    """æ ¼å¼åŒ–ç°ä»£é¡µé¢è¾“å‡ºï¼ˆæ ‡å‡† Markdownï¼‰"""
    output_lines = []
    
    output_lines.append(f"## ç¬¬ {page_data['page']} é¡µ\n")
    
    if page_data["text"]:
        output_lines.append(page_data["text"])
    else:
        output_lines.append("*(æ— è¯†åˆ«å†…å®¹)*")
    
    output_lines.append("")
    output_lines.append("---")
    output_lines.append("")
    
    return "\n".join(output_lines)


def save_quality_report(pdf_name: str, pages_data: List[Dict], doc_type: str, output_dir: str):
    """ä¿å­˜è´¨é‡æŠ¥å‘Šåˆ°å•ç‹¬æ–‡ä»¶"""
    import json
    
    report_file = Path(output_dir) / f"{pdf_name}_quality_report.json"
    
    total_pages = len(pages_data)
    avg_confidence = sum(p["avg_score"] for p in pages_data) / total_pages if total_pages > 0 else 0
    min_confidence = min(p["avg_score"] for p in pages_data) if pages_data else 0
    high_confidence_count = sum(1 for p in pages_data if p["avg_score"] >= 0.90)
    medium_confidence_count = sum(1 for p in pages_data if 0.70 <= p["avg_score"] < 0.90)
    low_confidence_count = sum(1 for p in pages_data if p["avg_score"] < 0.70)
    
    report = {
        "pdf_name": pdf_name,
        "report_time": datetime.now().isoformat(),
        "version": VERSION,
        "doc_type": doc_type,
        "total_pages": total_pages,
        "quality_stats": {
            "avg_confidence": round(avg_confidence, 4),
            "min_confidence": round(min_confidence, 4),
            "high_confidence_pages": high_confidence_count,
            "medium_confidence_pages": medium_confidence_count,
            "low_confidence_pages": low_confidence_count,
            "high_confidence_ratio": round(high_confidence_count / total_pages * 100, 1) if total_pages > 0 else 0
        },
        "low_confidence_pages": [
            {"page": p["page"], "score": round(p["avg_score"], 4)}
            for p in pages_data if p["avg_score"] < 0.70
        ]
    }
    
    with open(report_file, "w", encoding="utf-8") as f:
        json.dump(report, f, ensure_ascii=False, indent=2)
    
    print(f"  âœ“ è´¨é‡æŠ¥å‘Šï¼š{report_file.name}")
    
    print(f"\n  â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—")
    print(f"  â•‘  è´¨é‡æŠ¥å‘Šæ‘˜è¦                                            â•‘")
    print(f"  â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
    print(f"    æ–‡æ¡£ç±»å‹ï¼š{'å¤ç±' if doc_type == 'ancient' else 'ç°ä»£'}")
    print(f"    å¹³å‡ç½®ä¿¡åº¦ï¼š{avg_confidence:.4f}")
    print(f"    æœ€ä½ç½®ä¿¡åº¦ï¼š{min_confidence:.4f}")
    print(f"    â‰¥0.90 é¡µé¢ï¼š{high_confidence_count}/{total_pages} ({high_confidence_count/total_pages*100:.1f}%)")
    print(f"    0.70-0.90 é¡µé¢ï¼š{medium_confidence_count}/{total_pages} ({medium_confidence_count/total_pages*100:.1f}%)")
    print(f"    <0.70 é¡µé¢ï¼š{low_confidence_count}/{total_pages} ({low_confidence_count/total_pages*100:.1f}%)")


def process_pdf_smart(pdf_path: str, output_dir: str, report_dir: str, pipeline) -> Tuple[str, float]:
    """å¤„ç†å•ä¸ª PDFï¼ˆæ™ºèƒ½è¯†åˆ«ï¼‰"""
    start_time = time.time()
    pdf_name = Path(pdf_path).stem
    output_file = Path(output_dir) / f"{pdf_name}_ocr.md"
    
    print(f"\nå¤„ç†ï¼š{Path(pdf_path).name}")
    
    print(f"  CPU é¢„å–é¡µé¢åˆ°å†…å­˜...")
    prefetch_start = time.time()
    images = pdf_to_images_optimized(pdf_path)
    total_pages = len(images)
    prefetch_time = time.time() - prefetch_start
    print(f"  âœ“ é¢„å–å®Œæˆï¼Œè€—æ—¶{prefetch_time:.1f}ç§’")
    
    # æ™ºèƒ½è¯†åˆ«æ–‡æ¡£ç±»å‹ï¼ˆä½¿ç”¨ç¬¬ä¸€é¡µï¼‰
    print(f"  æ­£åœ¨è¯†åˆ«æ–‡æ¡£ç±»å‹...")
    first_page_data = process_page(images[0][1], 1, pipeline)
    doc_type = detect_document_type(pdf_name, first_page_data["text"])
    
    if doc_type == "ancient":
        print(f"  âœ“ è¯†åˆ«ä¸ºã€å¤ç±æ–‡æ¡£ã€‘â†’ ä½¿ç”¨ä»å³åˆ°å·¦ã€æ¡†çº¿ç‰ˆé¢")
    else:
        print(f"  âœ“ è¯†åˆ«ä¸ºã€ç°ä»£æ–‡æ¡£ã€‘â†’ ä½¿ç”¨æ ‡å‡† Markdown æ ¼å¼")
    
    page_cache = PageCache(max_pages=PERF_CONFIG["prefetch_pages"])
    for i, (page_num, img) in enumerate(images):
        page_cache.put((pdf_name, page_num), img)
    
    pages_data = []

    print(f"\n  å¼€å§‹ OCR è¯†åˆ«...")

    for page_num, img in images:
        result = process_page(img, page_num, pipeline)
        pages_data.append(result)

        # æ¯ 20 é¡µæ£€æŸ¥å¹¶æ¸…ç†æ˜¾å­˜ï¼ˆæ™ºèƒ½ç›‘æ§ï¼‰
        if page_num % 20 == 0:
            mem_mb = check_and_clear_gpu_memory(threshold_mb=14000)
            if mem_mb > 10000:
                print(f"  ğŸ“Š æ˜¾å­˜å ç”¨ï¼š{mem_mb/1024:.1f}GB")

        if page_num % 10 == 0:
            elapsed = time.time() - start_time
            ppm = page_num / (elapsed / 60) if elapsed > 0 else 0
            print(f"  è¿›åº¦ï¼š{page_num}/{total_pages} | GPU é€Ÿåº¦ï¼š{ppm:.1f}é¡µ/åˆ†é’Ÿ | ç½®ä¿¡åº¦ï¼š{result['avg_score']:.3f}")
            sys.stdout.flush()

    # å¤„ç†å®Œæˆåæ¸…ç†æ˜¾å­˜
    check_and_clear_gpu_memory(threshold_mb=10000)
    
    page_cache.clear()
    images.clear()

    # ä¿å­˜ OCR æ–‡æ¡£ï¼ˆç²¾ç®€æ ¼å¼ï¼Œæ— æ–‡ä»¶å¤´ï¼‰
    with open(output_file, "w", encoding="utf-8") as f:
        for page_data in pages_data:
            if doc_type == "ancient":
                f.write(format_page_ancient(page_data))
            else:
                f.write(format_page_modern(page_data))
            f.write("\n\n")

    # ä¿å­˜è´¨é‡æŠ¥å‘Š
    save_quality_report(pdf_name, pages_data, doc_type, report_dir)
    
    elapsed = time.time() - start_time
    ppm = total_pages / (elapsed / 60) if elapsed > 0 else 0
    
    print(f"  âœ“ è¾“å‡ºï¼š{output_file.name}")
    print(f"  âœ“ é€Ÿåº¦ï¼š{ppm:.1f}é¡µ/åˆ†é’Ÿ")
    
    return str(output_file), ppm


def load_state() -> Dict:
    """åŠ è½½å¤„ç†çŠ¶æ€"""
    import json
    if os.path.exists(STATE_FILE):
        with open(STATE_FILE, "r", encoding="utf-8") as f:
            return json.load(f)
    return {}


def save_state(state: Dict):
    """ä¿å­˜å¤„ç†çŠ¶æ€"""
    import json
    with open(STATE_FILE, "w", encoding="utf-8") as f:
        json.dump(state, f, ensure_ascii=False, indent=2)


def scan_pdfs(folder: str) -> List[str]:
    """æ‰«æ PDF"""
    pdf_files = []
    for f in os.listdir(folder):
        fp = os.path.join(folder, f)
        if os.path.isfile(fp) and f.lower().endswith(".pdf"):
            pdf_files.append(fp)
    return sorted(pdf_files)


def main():
    """ä¸»å‡½æ•°"""
    print("="*70)
    print(f"ğŸš€ PDF æ‰¹é‡ OCR - {VERSION} æ™ºèƒ½è¯†åˆ«ç‰ˆ")
    print(f"è°ƒæ•´ï¼š{VERSION_NOTE}")
    print(f"ç›®æ ‡ï¼š{TARGET_SPEED} é¡µ/åˆ†é’Ÿ")
    print("="*70)
    
    import paddle
    if paddle.is_compiled_with_cuda():
        gpu_name = paddle.device.cuda.get_device_name(0)
        gpu_mem = paddle.device.cuda.get_device_properties(0).total_memory / 1024**3
        print(f"âœ… GPU: {gpu_name} | æ˜¾å­˜ï¼š{gpu_mem:.1f}GB")
    else:
        print("âš ï¸  è¿è¡Œæ¨¡å¼ï¼šCPU")
    
    cpu_count = multiprocessing.cpu_count()
    print(f"âœ… CPU: {cpu_count} æ ¸å¿ƒ | {PERF_CONFIG['cpu_workers']} çº¿ç¨‹è§£ç ")
    print(f"âœ… å†…å­˜ï¼š96GB | é¢„å–ç¼“å­˜ï¼š{PERF_CONFIG['prefetch_pages']} é¡µ")
    print("="*70)
    
    os.makedirs(OUTPUT_DIR, exist_ok=True)
    os.makedirs(REPORT_DIR, exist_ok=True)
    
    state = load_state()
    processed = state.get("processed", [])
    
    print(f"\nğŸ“‚ æ‰«æç›®å½•ï¼š{INPUT_DIR}")
    pdf_files = scan_pdfs(INPUT_DIR)
    
    new_files = [f for f in pdf_files if f not in processed]
    
    if not new_files:
        print("âš ï¸  æœªæ‰¾åˆ°æ–° PDF æ–‡ä»¶")
        return
    
    print(f"ğŸ“Š å…±å‘ç° {len(pdf_files)} ä¸ª PDF æ–‡ä»¶")
    print(f"ğŸ“Š å¾…å¤„ç† {len(new_files)} ä¸ª PDF æ–‡ä»¶")
    
    print("\nåˆå§‹åŒ– PaddleOCR æµæ°´çº¿...")
    pipeline = init_ocr_pipeline()
    
    print(f"\nå¼€å§‹æ‰¹é‡å¤„ç†...")
    for idx, pdf in enumerate(new_files, 1):
        print(f"\n[{idx}/{len(new_files)}]")
        try:
            output, speed = process_pdf_smart(pdf, OUTPUT_DIR, REPORT_DIR, pipeline)
            
            processed.append(pdf)
            state["processed"] = processed
            state["last_updated"] = datetime.now().isoformat()
            state["last_file"] = pdf
            state["last_speed"] = speed
            state["version"] = VERSION
            save_state(state)
            
        except Exception as e:
            print(f"  âŒ é”™è¯¯ï¼š{e}")
            import traceback
            traceback.print_exc()
    
    print("\n" + "="*70)
    print("ğŸ‰ æ‰¹é‡å¤„ç†å®Œæˆï¼")
    print(f"ğŸ“ OCR è¾“å‡ºç›®å½•ï¼š{OUTPUT_DIR}")
    print(f"ğŸ“ è´¨é‡æŠ¥å‘Šç›®å½•ï¼š{REPORT_DIR}")
    print("="*70)


if __name__ == "__main__":
    main()
